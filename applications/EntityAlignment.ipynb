{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "import  numpy as np\n",
    "from    tqdm import tqdm\n",
    "import  time\n",
    "\n",
    "import  rdflib\n",
    "from    sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from    src.utils import *\n",
    "from    src.gnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplets found: 7101\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "g = rdflib.Graph()\n",
    "g.parse('../data/oaei/h2m_map_typed.ttl')\n",
    "\n",
    "print(f'Triplets found: %d' % len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = list(set(g.predicates()))\n",
    "nodes = list(set(g.subjects()).union(set(g.objects())))\n",
    "\n",
    "relations_dict = {rel: i for i, rel in enumerate(relations)}\n",
    "nodes_dict = {node: i for i, node in enumerate(nodes)}\n",
    "\n",
    "nodes_dict_rev = {value: key for key, value in nodes_dict.items()}\n",
    "relations_dict_rev = {value: key for key, value in relations_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(g, nodes_dict, relations_dict)\n",
    "data = split_edges(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  edge_index=[2, 7101],\n",
       "  edge_type=[7101],\n",
       "  val_pos_edge_index=[2, 0],\n",
       "  val_edge_type=[0],\n",
       "  test_pos_edge_index=[2, 1420],\n",
       "  test_edge_type=[1420],\n",
       "  train_pos_edge_index=[2, 5681],\n",
       "  train_edge_type=[5681]\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6932,Hits@1: 0.817, Hits@10: 0.896\n",
      "Epoch: 100, Loss: 0.6932,Hits@1: 0.832, Hits@10: 0.904\n",
      "Run time: 142 seconds, 2 minutes\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "model = GNN()\n",
    "\n",
    "for epoch in range(100+1):\n",
    "    loss = model._train(data, len(nodes), len(relations))\n",
    "    if (epoch % 100) == 0:\n",
    "        hits1, hits10 = model._eval(data)\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f},'+ \n",
    "              f'Hits@1: {hits1:.3f}, Hits@10: {hits10:.3f}')\n",
    "\n",
    "torch.save(model, f'../models/RGCN_h2m_maps')\n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print(f'Run time: {elapsed_time:.0f} seconds, {elapsed_time/60:.0f} minutes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIDAVA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
